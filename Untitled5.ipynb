{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.datasets import cifar10\n",
    "from keras import regularizers\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    " def lr_schedule(epoch):\n",
    "    lrate = 0.001\n",
    "    if epoch > 75:\n",
    "        lrate = 0.0005\n",
    "    elif epoch > 100:\n",
    "        lrate = 0.0003       \n",
    "    return lrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#z-score\n",
    "mean = np.mean(x_train,axis=(0,1,2,3))\n",
    "std = np.std(x_train,axis=(0,1,2,3))\n",
    "x_train = (x_train-mean)/(std+1e-7)\n",
    "x_test = (x_test-mean)/(std+1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "y_train = np_utils.to_categorical(y_train,num_classes)\n",
    "y_test = np_utils.to_categorical(y_test,num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                20490     \n",
      "=================================================================\n",
      "Total params: 309,290\n",
      "Trainable params: 308,394\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "weight_decay = 1e-4\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay), input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    " \n",
    "model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.3))\n",
    " \n",
    "model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    " \n",
    "model.add(Flatten())\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    " \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    )\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training\n",
    "batch_size = 64\n",
    " \n",
    "opt_rms = keras.optimizers.rmsprop(lr=0.001,decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt_rms, metrics=['accuracy'])\n",
    "model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\\\n",
    "                    steps_per_epoch=x_train.shape[0] // batch_size,epochs=125,\\\n",
    "                    verbose=1,validation_data=(x_test,y_test),callbacks=[LearningRateScheduler(lr_schedule)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/125\n",
      "781/781 [==============================] - 1160s 1s/step - loss: 1.9168 - acc: 0.4257 - val_loss: 1.4039 - val_acc: 0.5651\n",
      "Epoch 2/125\n",
      "781/781 [==============================] - 1084s 1s/step - loss: 1.3097 - acc: 0.5825 - val_loss: 1.2847 - val_acc: 0.6221\n",
      "Epoch 3/125\n",
      "781/781 [==============================] - 1402s 2s/step - loss: 1.1138 - acc: 0.6478 - val_loss: 1.0708 - val_acc: 0.6786\n",
      "Epoch 4/125\n",
      "781/781 [==============================] - 1759s 2s/step - loss: 1.0119 - acc: 0.6812 - val_loss: 1.0031 - val_acc: 0.7032\n",
      "Epoch 5/125\n",
      "781/781 [==============================] - 1777s 2s/step - loss: 0.9484 - acc: 0.7063 - val_loss: 0.9275 - val_acc: 0.7287\n",
      "Epoch 6/125\n",
      "781/781 [==============================] - 1820s 2s/step - loss: 0.8960 - acc: 0.7286 - val_loss: 0.8208 - val_acc: 0.7660\n",
      "Epoch 7/125\n",
      "781/781 [==============================] - 2035s 3s/step - loss: 0.8529 - acc: 0.7423 - val_loss: 0.8422 - val_acc: 0.7577\n",
      "Epoch 8/125\n",
      "781/781 [==============================] - 2114s 3s/step - loss: 0.8254 - acc: 0.7547 - val_loss: 0.7841 - val_acc: 0.7774\n",
      "Epoch 9/125\n",
      "781/781 [==============================] - 1167s 1s/step - loss: 0.8052 - acc: 0.7619 - val_loss: 0.7423 - val_acc: 0.7891\n",
      "Epoch 10/125\n",
      "781/781 [==============================] - 1160s 1s/step - loss: 0.7850 - acc: 0.7702 - val_loss: 0.7468 - val_acc: 0.7933\n",
      "Epoch 11/125\n",
      "781/781 [==============================] - 1165s 1s/step - loss: 0.7684 - acc: 0.7769 - val_loss: 0.7609 - val_acc: 0.7921\n",
      "Epoch 12/125\n",
      "781/781 [==============================] - 1135s 1s/step - loss: 0.7459 - acc: 0.7858 - val_loss: 0.7035 - val_acc: 0.8122\n",
      "Epoch 13/125\n",
      "781/781 [==============================] - 1276s 2s/step - loss: 0.7335 - acc: 0.7905 - val_loss: 0.6976 - val_acc: 0.8112\n",
      "Epoch 14/125\n",
      "781/781 [==============================] - 1172s 2s/step - loss: 0.7173 - acc: 0.7974 - val_loss: 0.6396 - val_acc: 0.8290\n",
      "Epoch 15/125\n",
      "781/781 [==============================] - 1082s 1s/step - loss: 0.7165 - acc: 0.7980 - val_loss: 0.6701 - val_acc: 0.8207\n",
      "Epoch 16/125\n",
      "781/781 [==============================] - 1105s 1s/step - loss: 0.7036 - acc: 0.8035 - val_loss: 0.6014 - val_acc: 0.8395\n",
      "Epoch 17/125\n",
      "781/781 [==============================] - 1108s 1s/step - loss: 0.6922 - acc: 0.8094 - val_loss: 0.7143 - val_acc: 0.8095\n",
      "Epoch 18/125\n",
      "781/781 [==============================] - 1095s 1s/step - loss: 0.6900 - acc: 0.8100 - val_loss: 0.6713 - val_acc: 0.8249\n",
      "Epoch 19/125\n",
      "781/781 [==============================] - 1175s 2s/step - loss: 0.6798 - acc: 0.8123 - val_loss: 0.7279 - val_acc: 0.8097\n",
      "Epoch 20/125\n",
      "781/781 [==============================] - 1114s 1s/step - loss: 0.6780 - acc: 0.8145 - val_loss: 0.6843 - val_acc: 0.8207\n",
      "Epoch 21/125\n",
      "781/781 [==============================] - 1111s 1s/step - loss: 0.6737 - acc: 0.8170 - val_loss: 0.6663 - val_acc: 0.8276\n",
      "Epoch 22/125\n",
      "781/781 [==============================] - 1089s 1s/step - loss: 0.6691 - acc: 0.8186 - val_loss: 0.7474 - val_acc: 0.8137\n",
      "Epoch 23/125\n",
      "781/781 [==============================] - 1104s 1s/step - loss: 0.6576 - acc: 0.8225 - val_loss: 0.6847 - val_acc: 0.8237\n",
      "Epoch 24/125\n",
      "781/781 [==============================] - 1030s 1s/step - loss: 0.6592 - acc: 0.8232 - val_loss: 0.6418 - val_acc: 0.8348\n",
      "Epoch 25/125\n",
      "781/781 [==============================] - 1083s 1s/step - loss: 0.6598 - acc: 0.8221 - val_loss: 0.6384 - val_acc: 0.8373\n",
      "Epoch 26/125\n",
      "781/781 [==============================] - 1065s 1s/step - loss: 0.6476 - acc: 0.8263 - val_loss: 0.6857 - val_acc: 0.8253\n",
      "Epoch 27/125\n",
      "781/781 [==============================] - 1015s 1s/step - loss: 0.6474 - acc: 0.8290 - val_loss: 0.6079 - val_acc: 0.8480\n",
      "Epoch 28/125\n",
      "781/781 [==============================] - 1024s 1s/step - loss: 0.6458 - acc: 0.8298 - val_loss: 0.6799 - val_acc: 0.8236\n",
      "Epoch 29/125\n",
      "781/781 [==============================] - 1020s 1s/step - loss: 0.6445 - acc: 0.8289 - val_loss: 0.6643 - val_acc: 0.8321\n",
      "Epoch 30/125\n",
      "781/781 [==============================] - 989s 1s/step - loss: 0.6421 - acc: 0.8306 - val_loss: 0.6511 - val_acc: 0.8333\n",
      "Epoch 31/125\n",
      "781/781 [==============================] - 1026s 1s/step - loss: 0.6395 - acc: 0.8311 - val_loss: 0.6189 - val_acc: 0.8443\n",
      "Epoch 32/125\n",
      "781/781 [==============================] - 1022s 1s/step - loss: 0.6337 - acc: 0.8333 - val_loss: 0.6304 - val_acc: 0.8395\n",
      "Epoch 33/125\n",
      "781/781 [==============================] - 1001s 1s/step - loss: 0.6340 - acc: 0.8360 - val_loss: 0.6312 - val_acc: 0.8427\n",
      "Epoch 34/125\n",
      "781/781 [==============================] - 1008s 1s/step - loss: 0.6257 - acc: 0.8374 - val_loss: 0.6230 - val_acc: 0.8456\n",
      "Epoch 35/125\n",
      "781/781 [==============================] - 1037s 1s/step - loss: 0.6218 - acc: 0.8373 - val_loss: 0.5906 - val_acc: 0.8580\n",
      "Epoch 36/125\n",
      "781/781 [==============================] - 1023s 1s/step - loss: 0.6267 - acc: 0.8361 - val_loss: 0.6336 - val_acc: 0.8398\n",
      "Epoch 37/125\n",
      "781/781 [==============================] - 990s 1s/step - loss: 0.6249 - acc: 0.8369 - val_loss: 0.6113 - val_acc: 0.8467\n",
      "Epoch 38/125\n",
      "781/781 [==============================] - 1026s 1s/step - loss: 0.6197 - acc: 0.8385 - val_loss: 0.5738 - val_acc: 0.8604\n",
      "Epoch 39/125\n",
      "781/781 [==============================] - 1025s 1s/step - loss: 0.6204 - acc: 0.8386 - val_loss: 0.6323 - val_acc: 0.8415\n",
      "Epoch 40/125\n",
      "781/781 [==============================] - 1005s 1s/step - loss: 0.6158 - acc: 0.8417 - val_loss: 0.5881 - val_acc: 0.8536\n",
      "Epoch 41/125\n",
      "781/781 [==============================] - 985s 1s/step - loss: 0.6204 - acc: 0.8411 - val_loss: 0.6861 - val_acc: 0.8330\n",
      "Epoch 42/125\n",
      "781/781 [==============================] - 993s 1s/step - loss: 0.6189 - acc: 0.8401 - val_loss: 0.5645 - val_acc: 0.8631\n",
      "Epoch 43/125\n",
      "781/781 [==============================] - 1011s 1s/step - loss: 0.6095 - acc: 0.8436 - val_loss: 0.5728 - val_acc: 0.8568\n",
      "Epoch 44/125\n",
      "781/781 [==============================] - 991s 1s/step - loss: 0.6134 - acc: 0.8417 - val_loss: 0.6261 - val_acc: 0.8513\n",
      "Epoch 45/125\n",
      "781/781 [==============================] - 1017s 1s/step - loss: 0.6085 - acc: 0.8444 - val_loss: 0.6143 - val_acc: 0.8501\n",
      "Epoch 46/125\n",
      "781/781 [==============================] - 1033s 1s/step - loss: 0.6084 - acc: 0.8444 - val_loss: 0.6127 - val_acc: 0.8518\n",
      "Epoch 47/125\n",
      "781/781 [==============================] - 994s 1s/step - loss: 0.6083 - acc: 0.8440 - val_loss: 0.6266 - val_acc: 0.8468\n",
      "Epoch 48/125\n",
      "781/781 [==============================] - 1023s 1s/step - loss: 0.6096 - acc: 0.8419 - val_loss: 0.5620 - val_acc: 0.8644\n",
      "Epoch 49/125\n",
      "781/781 [==============================] - 1016s 1s/step - loss: 0.6068 - acc: 0.8445 - val_loss: 0.5918 - val_acc: 0.8578\n",
      "Epoch 50/125\n",
      "781/781 [==============================] - 1011s 1s/step - loss: 0.6054 - acc: 0.8441 - val_loss: 0.6054 - val_acc: 0.8528\n",
      "Epoch 51/125\n",
      "781/781 [==============================] - 1020s 1s/step - loss: 0.6005 - acc: 0.8469 - val_loss: 0.6467 - val_acc: 0.8422\n",
      "Epoch 52/125\n",
      "781/781 [==============================] - 1023s 1s/step - loss: 0.6005 - acc: 0.8460 - val_loss: 0.6333 - val_acc: 0.8495\n",
      "Epoch 53/125\n",
      "781/781 [==============================] - 1022s 1s/step - loss: 0.6032 - acc: 0.8474 - val_loss: 0.6463 - val_acc: 0.8410\n",
      "Epoch 54/125\n",
      "781/781 [==============================] - 993s 1s/step - loss: 0.6030 - acc: 0.8468 - val_loss: 0.6191 - val_acc: 0.8482\n",
      "Epoch 55/125\n",
      "781/781 [==============================] - 1023s 1s/step - loss: 0.5993 - acc: 0.8476 - val_loss: 0.5737 - val_acc: 0.8623\n",
      "Epoch 56/125\n",
      "781/781 [==============================] - 1019s 1s/step - loss: 0.5962 - acc: 0.8476 - val_loss: 0.5967 - val_acc: 0.8544\n",
      "Epoch 57/125\n",
      "781/781 [==============================] - 1003s 1s/step - loss: 0.5966 - acc: 0.8492 - val_loss: 0.5637 - val_acc: 0.8637\n",
      "Epoch 58/125\n",
      "781/781 [==============================] - 998s 1s/step - loss: 0.5930 - acc: 0.8485 - val_loss: 0.5848 - val_acc: 0.8582\n",
      "Epoch 59/125\n",
      "781/781 [==============================] - 1014s 1s/step - loss: 0.5928 - acc: 0.8506 - val_loss: 0.6123 - val_acc: 0.8520\n",
      "Epoch 60/125\n",
      "781/781 [==============================] - 1002s 1s/step - loss: 0.5906 - acc: 0.8485 - val_loss: 0.6088 - val_acc: 0.8527\n",
      "Epoch 61/125\n",
      "781/781 [==============================] - 1019s 1s/step - loss: 0.5911 - acc: 0.8499 - val_loss: 0.6085 - val_acc: 0.8512\n",
      "Epoch 62/125\n",
      "781/781 [==============================] - 991s 1s/step - loss: 0.5947 - acc: 0.8492 - val_loss: 0.5858 - val_acc: 0.8552\n",
      "Epoch 63/125\n",
      "781/781 [==============================] - 1027s 1s/step - loss: 0.5901 - acc: 0.8494 - val_loss: 0.6632 - val_acc: 0.8387\n",
      "Epoch 64/125\n",
      "781/781 [==============================] - 1021s 1s/step - loss: 0.5860 - acc: 0.8528 - val_loss: 0.6045 - val_acc: 0.8536\n",
      "Epoch 65/125\n",
      "781/781 [==============================] - 1005s 1s/step - loss: 0.5888 - acc: 0.8525 - val_loss: 0.6237 - val_acc: 0.8486\n",
      "Epoch 66/125\n",
      "781/781 [==============================] - 1018s 1s/step - loss: 0.5897 - acc: 0.8520 - val_loss: 0.7526 - val_acc: 0.8217\n",
      "Epoch 67/125\n",
      "781/781 [==============================] - 1094s 1s/step - loss: 0.5879 - acc: 0.8519 - val_loss: 0.5601 - val_acc: 0.8628\n",
      "Epoch 68/125\n",
      "781/781 [==============================] - 991s 1s/step - loss: 0.5893 - acc: 0.8520 - val_loss: 0.5681 - val_acc: 0.8665\n",
      "Epoch 69/125\n",
      "781/781 [==============================] - 1022s 1s/step - loss: 0.5869 - acc: 0.8516 - val_loss: 0.6357 - val_acc: 0.8434\n",
      "Epoch 70/125\n",
      "781/781 [==============================] - 1018s 1s/step - loss: 0.5809 - acc: 0.8534 - val_loss: 0.5870 - val_acc: 0.8574\n",
      "Epoch 71/125\n",
      "781/781 [==============================] - 997s 1s/step - loss: 0.5853 - acc: 0.8528 - val_loss: 0.6590 - val_acc: 0.8377\n",
      "Epoch 72/125\n",
      "781/781 [==============================] - 1025s 1s/step - loss: 0.5807 - acc: 0.8560 - val_loss: 0.5522 - val_acc: 0.8714\n",
      "Epoch 73/125\n",
      "781/781 [==============================] - 1011s 1s/step - loss: 0.5854 - acc: 0.8538 - val_loss: 0.5708 - val_acc: 0.8614\n",
      "Epoch 74/125\n",
      "781/781 [==============================] - 1026s 1s/step - loss: 0.5861 - acc: 0.8528 - val_loss: 0.5574 - val_acc: 0.8669\n",
      "Epoch 75/125\n",
      "781/781 [==============================] - 996s 1s/step - loss: 0.5831 - acc: 0.8530 - val_loss: 0.5797 - val_acc: 0.8628\n",
      "Epoch 76/125\n",
      "781/781 [==============================] - 1022s 1s/step - loss: 0.5776 - acc: 0.8547 - val_loss: 0.6748 - val_acc: 0.8349\n",
      "Epoch 77/125\n",
      "781/781 [==============================] - 1022s 1s/step - loss: 0.5381 - acc: 0.8660 - val_loss: 0.5520 - val_acc: 0.8655\n",
      "Epoch 78/125\n",
      "781/781 [==============================] - 1011s 1s/step - loss: 0.5147 - acc: 0.8730 - val_loss: 0.5341 - val_acc: 0.8743\n",
      "Epoch 79/125\n",
      "781/781 [==============================] - 1015s 1s/step - loss: 0.5115 - acc: 0.8740 - val_loss: 0.5464 - val_acc: 0.8691\n",
      "Epoch 80/125\n",
      "781/781 [==============================] - 1015s 1s/step - loss: 0.5084 - acc: 0.8731 - val_loss: 0.5943 - val_acc: 0.8581\n",
      "Epoch 81/125\n",
      "781/781 [==============================] - 1019s 1s/step - loss: 0.4938 - acc: 0.8771 - val_loss: 0.5219 - val_acc: 0.8743\n",
      "Epoch 82/125\n",
      "781/781 [==============================] - 1002s 1s/step - loss: 0.4939 - acc: 0.8782 - val_loss: 0.5339 - val_acc: 0.8730\n",
      "Epoch 83/125\n",
      "781/781 [==============================] - 1249s 2s/step - loss: 0.4896 - acc: 0.8786 - val_loss: 0.5198 - val_acc: 0.8779\n",
      "Epoch 84/125\n",
      "781/781 [==============================] - 1021s 1s/step - loss: 0.4863 - acc: 0.8789 - val_loss: 0.4841 - val_acc: 0.8865\n",
      "Epoch 85/125\n",
      "781/781 [==============================] - 1001s 1s/step - loss: 0.4834 - acc: 0.8780 - val_loss: 0.5314 - val_acc: 0.8685\n",
      "Epoch 86/125\n",
      "781/781 [==============================] - 1009s 1s/step - loss: 0.4771 - acc: 0.8805 - val_loss: 0.5135 - val_acc: 0.8749\n",
      "Epoch 87/125\n",
      "781/781 [==============================] - 1007s 1s/step - loss: 0.4766 - acc: 0.8797 - val_loss: 0.5204 - val_acc: 0.8743\n",
      "Epoch 88/125\n",
      "781/781 [==============================] - 1016s 1s/step - loss: 0.4804 - acc: 0.8779 - val_loss: 0.4984 - val_acc: 0.8795\n",
      "Epoch 89/125\n",
      "781/781 [==============================] - 1115s 1s/step - loss: 0.4731 - acc: 0.8801 - val_loss: 0.4814 - val_acc: 0.8851\n",
      "Epoch 90/125\n",
      " 17/781 [..............................] - ETA: 15:39 - loss: 0.4897 - acc: 0.87"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-bfa6253a3fbb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\\\n\u001b[0;32m      7\u001b[0m                     \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m125\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m                     verbose=1,validation_data=(x_test,y_test),callbacks=[LearningRateScheduler(lr_schedule)])\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\DIP\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DIP\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1413\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1414\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1415\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1416\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DIP\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    217\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 219\u001b[1;33m                 \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    220\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m                 \u001b[0mbatch_index\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DIP\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[0mt_before_callbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m             \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delta_ts_batch_end\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt_before_callbacks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[0mdelta_t_median\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delta_ts_batch_end\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DIP\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    326\u001b[0m         \u001b[1;31m# will be handled by on_epoch_end.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseen\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 328\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DIP\\lib\\site-packages\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, current, values)\u001b[0m\n\u001b[0;32m    354\u001b[0m             \u001b[0mprev_total_width\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_total_width\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dynamic_display\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 356\u001b[1;33m                 \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\b'\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mprev_total_width\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    357\u001b[0m                 \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DIP\\lib\\site-packages\\ipykernel\\iostream.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, string)\u001b[0m\n\u001b[0;32m    398\u001b[0m             \u001b[0mis_child\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_master_process\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m             \u001b[1;31m# only touch the buffer in the IO thread to avoid races\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 400\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    401\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_child\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m                 \u001b[1;31m# newlines imply flush in subprocesses\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DIP\\lib\\site-packages\\ipykernel\\iostream.py\u001b[0m in \u001b[0;36mschedule\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m    201\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_events\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m             \u001b[1;31m# wake event thread (message content is ignored)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 203\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event_pipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    204\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m             \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DIP\\lib\\site-packages\\zmq\\sugar\\socket.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[0;32m    390\u001b[0m                                  copy_threshold=self.copy_threshold)\n\u001b[0;32m    391\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 392\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSocket\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    394\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msend_multipart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg_parts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DIP\\lib\\site-packages\\zmq\\backend\\cython\\checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to disk\n",
    "model_json = model.to_json()\n",
    "with open('model.json', 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights('model.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-11-86201c61fda7>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-11-86201c61fda7>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    print('\\nTest result: %.3f loss: %.3f' % (scores[1]*100,scores[0])\u001b[0m\n\u001b[1;37m                                                                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "#testing\n",
    "scores = model.evaluate(x_test, y_test, batch_size=128, verbose=1)\n",
    "print('\\nTest result: %.3f loss: %.3f' % (scores[1]*100,scores[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
